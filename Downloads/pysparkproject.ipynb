{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "execution": {
          "iopub.execute_input": "2022-04-27T13:10:17.626825Z",
          "iopub.status.busy": "2022-04-27T13:10:17.626033Z",
          "iopub.status.idle": "2022-04-27T13:11:02.089004Z",
          "shell.execute_reply": "2022-04-27T13:11:02.088158Z"
        },
        "papermill": {
          "duration": 44.611178,
          "end_time": "2022-04-27T13:11:02.089148",
          "exception": false,
          "start_time": "2022-04-27T13:10:17.477970",
          "status": "completed"
        },
        "tags": [],
        "id": "MNilm7MZ-SzZ"
      },
      "outputs": [],
      "source": [
        "# Install Spark 3.5.0\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n",
        "\n",
        "# Install Findspark\n",
        "!pip install -q findspark\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "## creating a spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Midterm').getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.259646,
          "end_time": "2022-04-27T13:11:19.253606",
          "exception": false,
          "start_time": "2022-04-27T13:11:18.993960",
          "status": "completed"
        },
        "tags": [],
        "id": "pXWhGVHN-Szf"
      },
      "source": [
        "## Question 1:\n",
        "Read the data set from Google Drive, and create a new RDD with it. Show the first 20 rows and the schema of the Titanic RDD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2Rzz76RL1Zy",
        "outputId": "8d732ff7-c1c1-4ca3-97fd-d8760178b62b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "titanic_df = spark.read.csv('/content/gdrive/My Drive/Titanic-Dataset.csv', header=True, inferSchema=True)\n",
        "\n",
        "\n",
        "titanic_rdd = titanic_df.rdd"
      ],
      "metadata": {
        "id": "oCJ5_iEwMY8W"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(titanic_rdd.take(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TIkr_wvMX2n",
        "outputId": "b3e202d2-4ca7-449f-952b-c0a3e9963346"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Row(PassengerId=1, Survived=0, Pclass=3, Name='Braund, Mr. Owen Harris', Sex='male', Age=22.0, SibSp=1, Parch=0, Ticket='A/5 21171', Fare=7.25, Cabin=None, Embarked='S'), Row(PassengerId=2, Survived=1, Pclass=1, Name='Cumings, Mrs. John Bradley (Florence Briggs Thayer)', Sex='female', Age=38.0, SibSp=1, Parch=0, Ticket='PC 17599', Fare=71.2833, Cabin='C85', Embarked='C'), Row(PassengerId=3, Survived=1, Pclass=3, Name='Heikkinen, Miss. Laina', Sex='female', Age=26.0, SibSp=0, Parch=0, Ticket='STON/O2. 3101282', Fare=7.925, Cabin=None, Embarked='S'), Row(PassengerId=4, Survived=1, Pclass=1, Name='Futrelle, Mrs. Jacques Heath (Lily May Peel)', Sex='female', Age=35.0, SibSp=1, Parch=0, Ticket='113803', Fare=53.1, Cabin='C123', Embarked='S'), Row(PassengerId=5, Survived=0, Pclass=3, Name='Allen, Mr. William Henry', Sex='male', Age=35.0, SibSp=0, Parch=0, Ticket='373450', Fare=8.05, Cabin=None, Embarked='S'), Row(PassengerId=6, Survived=0, Pclass=3, Name='Moran, Mr. James', Sex='male', Age=None, SibSp=0, Parch=0, Ticket='330877', Fare=8.4583, Cabin=None, Embarked='Q'), Row(PassengerId=7, Survived=0, Pclass=1, Name='McCarthy, Mr. Timothy J', Sex='male', Age=54.0, SibSp=0, Parch=0, Ticket='17463', Fare=51.8625, Cabin='E46', Embarked='S'), Row(PassengerId=8, Survived=0, Pclass=3, Name='Palsson, Master. Gosta Leonard', Sex='male', Age=2.0, SibSp=3, Parch=1, Ticket='349909', Fare=21.075, Cabin=None, Embarked='S'), Row(PassengerId=9, Survived=1, Pclass=3, Name='Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)', Sex='female', Age=27.0, SibSp=0, Parch=2, Ticket='347742', Fare=11.1333, Cabin=None, Embarked='S'), Row(PassengerId=10, Survived=1, Pclass=2, Name='Nasser, Mrs. Nicholas (Adele Achem)', Sex='female', Age=14.0, SibSp=1, Parch=0, Ticket='237736', Fare=30.0708, Cabin=None, Embarked='C'), Row(PassengerId=11, Survived=1, Pclass=3, Name='Sandstrom, Miss. Marguerite Rut', Sex='female', Age=4.0, SibSp=1, Parch=1, Ticket='PP 9549', Fare=16.7, Cabin='G6', Embarked='S'), Row(PassengerId=12, Survived=1, Pclass=1, Name='Bonnell, Miss. Elizabeth', Sex='female', Age=58.0, SibSp=0, Parch=0, Ticket='113783', Fare=26.55, Cabin='C103', Embarked='S'), Row(PassengerId=13, Survived=0, Pclass=3, Name='Saundercock, Mr. William Henry', Sex='male', Age=20.0, SibSp=0, Parch=0, Ticket='A/5. 2151', Fare=8.05, Cabin=None, Embarked='S'), Row(PassengerId=14, Survived=0, Pclass=3, Name='Andersson, Mr. Anders Johan', Sex='male', Age=39.0, SibSp=1, Parch=5, Ticket='347082', Fare=31.275, Cabin=None, Embarked='S'), Row(PassengerId=15, Survived=0, Pclass=3, Name='Vestrom, Miss. Hulda Amanda Adolfina', Sex='female', Age=14.0, SibSp=0, Parch=0, Ticket='350406', Fare=7.8542, Cabin=None, Embarked='S'), Row(PassengerId=16, Survived=1, Pclass=2, Name='Hewlett, Mrs. (Mary D Kingcome) ', Sex='female', Age=55.0, SibSp=0, Parch=0, Ticket='248706', Fare=16.0, Cabin=None, Embarked='S'), Row(PassengerId=17, Survived=0, Pclass=3, Name='Rice, Master. Eugene', Sex='male', Age=2.0, SibSp=4, Parch=1, Ticket='382652', Fare=29.125, Cabin=None, Embarked='Q'), Row(PassengerId=18, Survived=1, Pclass=2, Name='Williams, Mr. Charles Eugene', Sex='male', Age=None, SibSp=0, Parch=0, Ticket='244373', Fare=13.0, Cabin=None, Embarked='S'), Row(PassengerId=19, Survived=0, Pclass=3, Name='Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele)', Sex='female', Age=31.0, SibSp=1, Parch=0, Ticket='345763', Fare=18.0, Cabin=None, Embarked='S'), Row(PassengerId=20, Survived=1, Pclass=3, Name='Masselmani, Mrs. Fatima', Sex='female', Age=None, SibSp=0, Parch=0, Ticket='2649', Fare=7.225, Cabin=None, Embarked='C')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra Credit Opportunity!\n",
        "\n",
        "Convert the RDD into a Pandas Dataframe."
      ],
      "metadata": {
        "id": "EoLi2xUe_7nN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-27T13:11:27.357989Z",
          "iopub.status.busy": "2022-04-27T13:11:27.356933Z",
          "iopub.status.idle": "2022-04-27T13:11:27.766334Z",
          "shell.execute_reply": "2022-04-27T13:11:27.765609Z"
        },
        "papermill": {
          "duration": 0.668383,
          "end_time": "2022-04-27T13:11:27.766522",
          "exception": false,
          "start_time": "2022-04-27T13:11:27.098139",
          "status": "completed"
        },
        "tags": [],
        "id": "2NYwIzQE-Szk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a7126c-b4ba-4c73-ed60-7263a368233e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
            "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "titanic_df_from_rdd = spark.createDataFrame(titanic_rdd)\n",
        "\n",
        "\n",
        "titanic_pd_df = titanic_df_from_rdd.toPandas()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2:\n",
        "\n",
        "`sibsp` is the number of siblings/spouses onboard\n",
        "\n",
        "`parch` is the number of parents/children onboard\n",
        "\n",
        "Copy the contents of the `sibsp` to a new one with a clearer name, then re-name the `parch` column without adding a new column. Print the schema and the first 10 rows of the new RDD."
      ],
      "metadata": {
        "id": "1xND4iwb_joZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-27T13:11:32.490623Z",
          "iopub.status.busy": "2022-04-27T13:11:32.489937Z",
          "iopub.status.idle": "2022-04-27T13:11:32.708070Z",
          "shell.execute_reply": "2022-04-27T13:11:32.707243Z"
        },
        "papermill": {
          "duration": 0.480847,
          "end_time": "2022-04-27T13:11:32.708244",
          "exception": false,
          "start_time": "2022-04-27T13:11:32.227397",
          "status": "completed"
        },
        "tags": [],
        "id": "gvVewFud-Szm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0632ca9d-3fa4-40cc-f206-74676fc36b12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- PassengerId: long (nullable = true)\n",
            " |-- Survived: long (nullable = true)\n",
            " |-- Pclass: long (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- SibSp: long (nullable = true)\n",
            " |-- parents_children_onboard: long (nullable = true)\n",
            " |-- Ticket: string (nullable = true)\n",
            " |-- Fare: double (nullable = true)\n",
            " |-- Cabin: string (nullable = true)\n",
            " |-- Embarked: string (nullable = true)\n",
            " |-- siblings_spouses_onboard: long (nullable = true)\n",
            "\n",
            "+-----------+--------+------+--------------------+------+----+-----+------------------------+----------------+-------+-----+--------+------------------------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|parents_children_onboard|          Ticket|   Fare|Cabin|Embarked|siblings_spouses_onboard|\n",
            "+-----------+--------+------+--------------------+------+----+-----+------------------------+----------------+-------+-----+--------+------------------------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|                       0|       A/5 21171|   7.25| NULL|       S|                       1|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|                       0|        PC 17599|71.2833|  C85|       C|                       1|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|                       0|STON/O2. 3101282|  7.925| NULL|       S|                       0|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|                       0|          113803|   53.1| C123|       S|                       1|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|                       0|          373450|   8.05| NULL|       S|                       0|\n",
            "|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|                       0|          330877| 8.4583| NULL|       Q|                       0|\n",
            "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|                       0|           17463|51.8625|  E46|       S|                       0|\n",
            "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|                       1|          349909| 21.075| NULL|       S|                       3|\n",
            "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|                       2|          347742|11.1333| NULL|       S|                       0|\n",
            "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|                       0|          237736|30.0708| NULL|       C|                       1|\n",
            "+-----------+--------+------+--------------------+------+----+-----+------------------------+----------------+-------+-----+--------+------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "\n",
        "titanic_df_from_rdd = titanic_df_from_rdd.withColumn(\"siblings_spouses_onboard\", col(\"sibsp\"))\n",
        "\n",
        "\n",
        "titanic_df_from_rdd = titanic_df_from_rdd.withColumnRenamed(\"parch\", \"parents_children_onboard\")\n",
        "\n",
        "\n",
        "titanic_df_from_rdd.printSchema()\n",
        "\n",
        "\n",
        "titanic_df_from_rdd.show(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra Credit Opportunity!\n",
        "\n",
        "Count how many unique families were onboard the Titanic."
      ],
      "metadata": {
        "id": "d2iLl66YPZGA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-27T13:11:33.886857Z",
          "iopub.status.busy": "2022-04-27T13:11:33.886080Z",
          "iopub.status.idle": "2022-04-27T13:11:33.892430Z",
          "shell.execute_reply": "2022-04-27T13:11:33.891844Z"
        },
        "papermill": {
          "duration": 0.271837,
          "end_time": "2022-04-27T13:11:33.892550",
          "exception": false,
          "start_time": "2022-04-27T13:11:33.620713",
          "status": "completed"
        },
        "tags": [],
        "id": "SM4Bsq1q-Szo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6da5931b-ccb9-4390-88cd-43207d748b0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "720"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from pyspark.sql.functions import split, col\n",
        "\n",
        "\n",
        "titanic_df_with_family = titanic_df_from_rdd.withColumn(\"LastName\", split(col(\"Name\"), \",\")[0]) \\\n",
        "                                             .withColumn(\"FamilySize\", 1 + col(\"siblings_spouses_onboard\") + col(\"parents_children_onboard\"))\n",
        "\n",
        "unique_families_count = titanic_df_with_family.groupBy(\"LastName\", \"FamilySize\").count()\n",
        "\n",
        "\n",
        "number_of_unique_families = unique_families_count.count()\n",
        "\n",
        "number_of_unique_families\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3:\n",
        "\n",
        "Use Spark SQL to select the ten most expensive fares, and a 2nd query to select the ten least expensive fares."
      ],
      "metadata": {
        "id": "FyS6KfZ9APu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "titanic_df_from_rdd.createOrReplaceTempView(\"titanic_data\")\n",
        "\n"
      ],
      "metadata": {
        "id": "NpNkDMcxPrhO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "most_expensive_fares = spark.sql(\"\"\"\n",
        "    SELECT Fare, PassengerId, Name\n",
        "    FROM titanic_data\n",
        "    ORDER BY Fare DESC\n",
        "    LIMIT 10\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "most_expensive_fares.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ll8G2F_K4jJe",
        "outputId": "05fd62b4-1431-4141-e88c-e149e357a018"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+--------------------+\n",
            "|    Fare|PassengerId|                Name|\n",
            "+--------+-----------+--------------------+\n",
            "|512.3292|        680|Cardeza, Mr. Thom...|\n",
            "|512.3292|        259|    Ward, Miss. Anna|\n",
            "|512.3292|        738|Lesurer, Mr. Gust...|\n",
            "|   263.0|         89|Fortune, Miss. Ma...|\n",
            "|   263.0|         28|Fortune, Mr. Char...|\n",
            "|   263.0|        342|Fortune, Miss. Al...|\n",
            "|   263.0|        439|   Fortune, Mr. Mark|\n",
            "| 262.375|        312|Ryerson, Miss. Em...|\n",
            "| 262.375|        743|\"Ryerson, Miss. S...|\n",
            "|247.5208|        119|Baxter, Mr. Quigg...|\n",
            "+--------+-----------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "least_expensive_fares = spark.sql(\"\"\"\n",
        "    SELECT Fare, PassengerId, Name\n",
        "    FROM titanic_data\n",
        "    WHERE Fare > 0\n",
        "    ORDER BY Fare ASC\n",
        "    LIMIT 10\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "least_expensive_fares.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh-0aiB74-Uj",
        "outputId": "b6112e13-8553-4575-d925-b307ed510e75"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+--------------------+\n",
            "|  Fare|PassengerId|                Name|\n",
            "+------+-----------+--------------------+\n",
            "|4.0125|        379| Betros, Mr. Tannous|\n",
            "|   5.0|        873|Carlsson, Mr. Fra...|\n",
            "|6.2375|        327|Nysveen, Mr. Joha...|\n",
            "|6.4375|        844|Lemberopolous, Mr...|\n",
            "|  6.45|        819|Holm, Mr. John Fr...|\n",
            "|6.4958|        203|Johanson, Mr. Jak...|\n",
            "|6.4958|        372|Wiklund, Mr. Jako...|\n",
            "|  6.75|        144| Burke, Mr. Jeremiah|\n",
            "|  6.75|        655|\"Hegarty, Miss. H...|\n",
            "|6.8583|        412|     Hart, Mr. Henry|\n",
            "+------+-----------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4:\n",
        "\n",
        "Drop any rows with 2 or more null values. Print the counts for the number of rows before and after dropping. (You won't need to use the new RDD with the dropped rows after this question)"
      ],
      "metadata": {
        "id": "dEa6MwPbAehO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-27T13:11:37.044999Z",
          "iopub.status.busy": "2022-04-27T13:11:37.043963Z",
          "iopub.status.idle": "2022-04-27T13:11:37.056778Z",
          "shell.execute_reply": "2022-04-27T13:11:37.057370Z"
        },
        "papermill": {
          "duration": 0.283904,
          "end_time": "2022-04-27T13:11:37.057518",
          "exception": false,
          "start_time": "2022-04-27T13:11:36.773614",
          "status": "completed"
        },
        "tags": [],
        "id": "XbnacP9s-Sz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c55f36f3-c588-4998-9cd8-0325c20d1821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows before dropping: 891\n",
            "Number of rows after dropping: 733\n"
          ]
        }
      ],
      "source": [
        "\n",
        "before_drop_count = titanic_df_from_rdd.count()\n",
        "print(f\"Number of rows before dropping: {before_drop_count}\")\n",
        "\n",
        "\n",
        "titanic_df_dropped = titanic_df_from_rdd.dropna(thresh=len(titanic_df_from_rdd.columns) - 1)\n",
        "\n",
        "\n",
        "after_drop_count = titanic_df_dropped.count()\n",
        "print(f\"Number of rows after dropping: {after_drop_count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 5:\n",
        "\n",
        "The Titanic sank in 1912, but the Bureau of Labor Statistics didn't keep track of inflation until 1913. Write a UDF to convert the fare from 1913 dollars to today's dollars, and apply it to the `fare` column.\n",
        "\n",
        "- Hint: Use a library to find the Consumer Price Index (CPI) to adjust for inflation! Don't try to re-invent the wheel!"
      ],
      "metadata": {
        "id": "kiCzmV1yCL8d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-27T13:11:50.379870Z",
          "iopub.status.busy": "2022-04-27T13:11:50.379180Z",
          "iopub.status.idle": "2022-04-27T13:11:50.511327Z",
          "shell.execute_reply": "2022-04-27T13:11:50.511890Z"
        },
        "papermill": {
          "duration": 0.407512,
          "end_time": "2022-04-27T13:11:50.512035",
          "exception": false,
          "start_time": "2022-04-27T13:11:50.104523",
          "status": "completed"
        },
        "tags": [],
        "id": "zRijhqzh-S0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45ada58b-fec8-4e23-a63e-7ebb59000bd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cpi in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from cpi) (2.31.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from cpi) (8.1.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from cpi) (2.8.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from cpi) (1.5.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->cpi) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->cpi) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->cpi) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->cpi) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->cpi) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->cpi) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->cpi) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install cpi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cpi\n",
        "cpi.inflate(1, 1913, to=2023)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOZzXlPuM2fj",
        "outputId": "3cae87d8-c429-4b4f-b2f7-900a7148b297"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30.777979797979796"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "\n",
        "inflation_rate = 30.777979797979796\n",
        "\n",
        "def adjust_fare_for_inflation(fare):\n",
        "    adjusted_fare = fare * inflation_rate\n",
        "    return adjusted_fare\n",
        "\n",
        "\n",
        "adjust_fare_udf = udf(adjust_fare_for_inflation, DoubleType())\n",
        "\n",
        "\n",
        "titanic_df_adjusted_fare = titanic_df_from_rdd.withColumn(\"AdjustedFare\", adjust_fare_udf(\"Fare\"))\n",
        "\n",
        "\n",
        "titanic_df_adjusted_fare.select(\"Fare\", \"AdjustedFare\").show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YkDmp5_QNqp",
        "outputId": "6778d376-3927-4b26-fd92-b4e5d4583383"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+\n",
            "|   Fare|      AdjustedFare|\n",
            "+-------+------------------+\n",
            "|   7.25| 223.1403535353535|\n",
            "|71.2833|2193.9559673333333|\n",
            "|  7.925|243.91548989898988|\n",
            "|   53.1|1634.3107272727273|\n",
            "|   8.05| 247.7627373737374|\n",
            "| 8.4583| 260.3293865252525|\n",
            "|51.8625|1596.2229772727271|\n",
            "| 21.075| 648.6459242424241|\n",
            "|11.1333|342.66048248484844|\n",
            "|30.0708| 925.5184749090909|\n",
            "+-------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 6:\n",
        "\n",
        "Write an accumulator variables to counts minors (Persons under 18) who were onboard the Titanic"
      ],
      "metadata": {
        "id": "5i2VQI1fDkq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import AccumulatorParam\n",
        "\n",
        "\n",
        "class IntAccumulatorParam(AccumulatorParam):\n",
        "    def zero(self, initialValue):\n",
        "        return 0\n",
        "\n",
        "    def addInPlace(self, v1, v2):\n",
        "        return v1 + v2\n",
        "\n",
        "\n",
        "minors_count = spark.sparkContext.accumulator(0, IntAccumulatorParam())\n",
        "\n",
        "\n",
        "def count_minors(row):\n",
        "    age = row['Age']\n",
        "    if age is not None and age < 18:\n",
        "        minors_count.add(1)\n",
        "    return row\n",
        "\n",
        "\n",
        "titanic_df_from_rdd.rdd.foreach(count_minors)\n",
        "\n",
        "\n",
        "print(f\"Number of minors onboard: {minors_count.value}\")\n"
      ],
      "metadata": {
        "id": "h5ga9XHeDjhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bed39772-7aff-4bb5-eef3-43b0655631c9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of minors onboard: 113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra Credit Opportunity!\n",
        "\n",
        "The [Birkenhead drill](https://en.wikipedia.org/wiki/Women_and_children_first) was meant to prioritize the lives of women and children in a life-threatening situation, and was commonplace on navel vessels in 1912.\n",
        "\n",
        "Find the ratio of women and minors who survived/perished compared to men 18 and older."
      ],
      "metadata": {
        "id": "-cMtsLlDdZdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when, col\n",
        "\n",
        "\n",
        "classified_df = titanic_df_from_rdd.withColumn(\n",
        "    \"Group\",\n",
        "    when((col(\"Sex\") == \"female\") | (col(\"Age\") < 18), \"Women_and_Minors\")\n",
        "    .otherwise(\"Men_18_and_Over\")\n",
        ")\n",
        "\n",
        "\n",
        "survival_counts = classified_df.groupBy(\"Group\", \"Survived\").count()\n",
        "\n",
        "\n",
        "survival_ratio = survival_counts.groupBy(\"Group\").pivot(\"Survived\").sum(\"count\")\n",
        "\n",
        "\n",
        "survival_ratio = survival_ratio.withColumn(\n",
        "    \"SurvivalRatio\",\n",
        "    col(\"1\") / (col(\"1\") + col(\"0\"))\n",
        ").select(\"Group\", \"SurvivalRatio\")\n",
        "\n",
        "survival_ratio.show()\n"
      ],
      "metadata": {
        "id": "C4t1KfEOej5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9cc4dd-f6a8-41b1-8002-2acae3093875"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-------------------+\n",
            "|           Group|      SurvivalRatio|\n",
            "+----------------+-------------------+\n",
            "|Women_and_Minors| 0.6881720430107527|\n",
            "| Men_18_and_Over|0.16570327552986513|\n",
            "+----------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 7:\n",
        "\n",
        "In the `embarked` column, each letter represents where the passenger embarked on their voyage from. Store the below information in a broadcast variable, and add an additional column with the full name of the port using the information in the broadcast variable.\n",
        "\n",
        "C = Cherbourg\n",
        "Q = Queenstown\n",
        "S = Southampton"
      ],
      "metadata": {
        "id": "8wHXdJUQGMSG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-27T13:11:51.057793Z",
          "iopub.status.busy": "2022-04-27T13:11:51.057069Z",
          "iopub.status.idle": "2022-04-27T13:11:51.344309Z",
          "shell.execute_reply": "2022-04-27T13:11:51.343614Z"
        },
        "papermill": {
          "duration": 0.561076,
          "end_time": "2022-04-27T13:11:51.344434",
          "exception": false,
          "start_time": "2022-04-27T13:11:50.783358",
          "status": "completed"
        },
        "scrolled": false,
        "tags": [],
        "id": "TBw8Rn-W-S0D"
      },
      "outputs": [],
      "source": [
        "embarked_mapping = {\n",
        "    \"C\": \"Cherbourg\",\n",
        "    \"Q\": \"Queenstown\",\n",
        "    \"S\": \"Southampton\"\n",
        "}\n",
        "\n",
        "\n",
        "broadcast = spark.sparkContext.broadcast(embarked_mapping)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "\n",
        "def get_full_port_name(code):\n",
        "    return broadcast.value.get(code, \"Unknown\")\n",
        "\n",
        "\n",
        "get_full_port_name_udf = udf(get_full_port_name, StringType())\n",
        "\n",
        "\n",
        "titanic_df_with_port_name = titanic_df_from_rdd.withColumn(\"PortFullName\", get_full_port_name_udf(col(\"Embarked\")))\n",
        "\n",
        "\n",
        "titanic_df_with_port_name.select(\"Embarked\", \"PortFullName\").show()\n",
        "titanic_df_with_port_name.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcyzsFmeTn7-",
        "outputId": "edf8ebc7-196a-4ff5-cbac-8d991d7d224f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------+\n",
            "|Embarked|PortFullName|\n",
            "+--------+------------+\n",
            "|       S| Southampton|\n",
            "|       C|   Cherbourg|\n",
            "|       S| Southampton|\n",
            "|       S| Southampton|\n",
            "|       S| Southampton|\n",
            "|       Q|  Queenstown|\n",
            "|       S| Southampton|\n",
            "|       S| Southampton|\n",
            "|       S| Southampton|\n",
            "|       C|   Cherbourg|\n",
            "|       S| Southampton|\n",
            "|       S| Southampton|\n",
            "|       S| Southampton|\n",
            "|       S| Southampton|\n",
            "|       S| Southampton|\n",
            "|       S| Southampton|\n",
            "|       Q|  Queenstown|\n",
            "|       S| Southampton|\n",
            "|       S| Southampton|\n",
            "|       C|   Cherbourg|\n",
            "+--------+------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-----------+--------+------+--------------------+------+----+-----+------------------------+----------------+-------+-----+--------+------------------------+------------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|parents_children_onboard|          Ticket|   Fare|Cabin|Embarked|siblings_spouses_onboard|PortFullName|\n",
            "+-----------+--------+------+--------------------+------+----+-----+------------------------+----------------+-------+-----+--------+------------------------+------------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|                       0|       A/5 21171|   7.25| NULL|       S|                       1| Southampton|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|                       0|        PC 17599|71.2833|  C85|       C|                       1|   Cherbourg|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|                       0|STON/O2. 3101282|  7.925| NULL|       S|                       0| Southampton|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|                       0|          113803|   53.1| C123|       S|                       1| Southampton|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|                       0|          373450|   8.05| NULL|       S|                       0| Southampton|\n",
            "|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|                       0|          330877| 8.4583| NULL|       Q|                       0|  Queenstown|\n",
            "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|                       0|           17463|51.8625|  E46|       S|                       0| Southampton|\n",
            "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|                       1|          349909| 21.075| NULL|       S|                       3| Southampton|\n",
            "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|                       2|          347742|11.1333| NULL|       S|                       0| Southampton|\n",
            "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|                       0|          237736|30.0708| NULL|       C|                       1|   Cherbourg|\n",
            "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|                       1|         PP 9549|   16.7|   G6|       S|                       1| Southampton|\n",
            "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|                       0|          113783|  26.55| C103|       S|                       0| Southampton|\n",
            "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|                       0|       A/5. 2151|   8.05| NULL|       S|                       0| Southampton|\n",
            "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|                       5|          347082| 31.275| NULL|       S|                       1| Southampton|\n",
            "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|                       0|          350406| 7.8542| NULL|       S|                       0| Southampton|\n",
            "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|                       0|          248706|   16.0| NULL|       S|                       0| Southampton|\n",
            "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|                       1|          382652| 29.125| NULL|       Q|                       4|  Queenstown|\n",
            "|         18|       1|     2|Williams, Mr. Cha...|  male|NULL|    0|                       0|          244373|   13.0| NULL|       S|                       0| Southampton|\n",
            "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|                       0|          345763|   18.0| NULL|       S|                       1| Southampton|\n",
            "|         20|       1|     3|Masselmani, Mrs. ...|female|NULL|    0|                       0|            2649|  7.225| NULL|       C|                       0|   Cherbourg|\n",
            "+-----------+--------+------+--------------------+------+----+-----+------------------------+----------------+-------+-----+--------+------------------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 8:\n",
        "\n",
        "Find the ratio of survived/perished passengers for each Passenger Class or `pclass`"
      ],
      "metadata": {
        "id": "ZW5KF8hCLFP-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-27T13:12:53.915515Z",
          "iopub.status.busy": "2022-04-27T13:12:53.914814Z",
          "iopub.status.idle": "2022-04-27T13:12:53.954924Z",
          "shell.execute_reply": "2022-04-27T13:12:53.954301Z"
        },
        "papermill": {
          "duration": 0.3412,
          "end_time": "2022-04-27T13:12:53.955043",
          "exception": false,
          "start_time": "2022-04-27T13:12:53.613843",
          "status": "completed"
        },
        "tags": [],
        "id": "tivJUUwP-S08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e022be7-fb63-41a1-d700-d05dceac318e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+--------+------------------+\n",
            "|Pclass|Survived|Perished|     SurvivalRatio|\n",
            "+------+--------+--------+------------------+\n",
            "|     1|     136|      80| 1.699997875002656|\n",
            "|     3|     119|     372|0.3198923871257024|\n",
            "|     2|      87|      97|0.8969062918491836|\n",
            "+------+--------+--------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "survival_counts = titanic_df_with_port_name.groupBy(\"Pclass\", \"Survived\").count()\n",
        "\n",
        "\n",
        "pivot_df = survival_counts.groupBy(\"Pclass\").pivot(\"Survived\").sum(\"count\").withColumnRenamed(\"1\", \"Survived\").withColumnRenamed(\"0\", \"Perished\")\n",
        "\n",
        "\n",
        "ratio_df = pivot_df.withColumn(\"SurvivalRatio\", col(\"Survived\") / (col(\"Perished\") + 0.0001))\n",
        "\n",
        "\n",
        "ratio_df.select(\"Pclass\", \"Survived\", \"Perished\", \"SurvivalRatio\").show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 9:\n",
        "\n",
        "Randomly split the data 70/30 into training/test data, and count the number if rows in each. Then build a Random Forrest Classifier on the features `pclass`,`sex`,`age`,`sibsp`, and `parch`."
      ],
      "metadata": {
        "id": "PnZV6yCvJPwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data, test_data = titanic_df_with_port_name.randomSplit([0.7, 0.3])\n",
        "\n",
        "train_count = train_data.count()\n",
        "test_count = test_data.count()\n",
        "\n",
        "print(f\"Number of rows in training data: {train_count}\")\n",
        "print(f\"Number of rows in test data: {test_count}\")"
      ],
      "metadata": {
        "id": "wSpXo5ebZtG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9a111de-636c-4e6d-93bc-217ce762b7f6"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in training data: 595\n",
            "Number of rows in test data: 296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Titanic Random Forest Example\").getOrCreate()\n",
        "\n",
        "median_age = titanic_df_with_port_name.approxQuantile(\"Age\", [0.5], 0.0)[0]\n",
        "titanic_df_filled = titanic_df_with_port_name.fillna({'Age': median_age, 'Embarked': 'S'})\n",
        "\n",
        "\n",
        "sex_indexer = StringIndexer(inputCol=\"Sex\", outputCol=\"SexIndexed\")\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"Pclass\", \"SexIndexed\", \"Age\", \"SibSp\", \"parents_children_onboard\"],\n",
        "    outputCol=\"features\")\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier(labelCol=\"Survived\", featuresCol=\"features\")\n",
        "\n",
        "\n",
        "pipeline = Pipeline(stages=[sex_indexer, assembler, rf])\n",
        "\n",
        "\n",
        "(train_data, test_data) = titanic_df_filled.randomSplit([0.7, 0.3])\n",
        "\n",
        "\n",
        "model = pipeline.fit(train_data)\n",
        "\n",
        "\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "\n",
        "predictions.select(\"prediction\", \"Survived\", \"features\").show(5)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHuacTSKXb_l",
        "outputId": "5078b25a-476c-4c33-e09e-d083bcd34734"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+--------------------+\n",
            "|prediction|Survived|            features|\n",
            "+----------+--------+--------------------+\n",
            "|       1.0|       1|[1.0,1.0,35.0,1.0...|\n",
            "|       1.0|       1|[2.0,1.0,14.0,1.0...|\n",
            "|       1.0|       1|[3.0,1.0,4.0,1.0,...|\n",
            "|       1.0|       1|[2.0,1.0,55.0,0.0...|\n",
            "|       0.0|       0|[3.0,1.0,31.0,1.0...|\n",
            "+----------+--------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra Credit Opportunity!\n",
        "\n",
        "Use the test data to validate the model."
      ],
      "metadata": {
        "id": "2zzJHGWtZmLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "\n",
        "binary_evaluator = BinaryClassificationEvaluator(labelCol=\"Survived\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "\n",
        "auc = binary_evaluator.evaluate(predictions)\n",
        "print(f\"Area under ROC curve: {auc}\")\n"
      ],
      "metadata": {
        "id": "6XBFrp_yL9A-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd3b7ab-cfe5-4d53-91ac-7e198f47f06e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Area under ROC curve: 0.8672633495145631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 10:\n",
        "\n",
        "Show the probability of the following two passengers surviving the Titanic shipwreck:\n",
        "\n",
        "---\n",
        "\n",
        "| pclass | name                | sex    | age | sibsp | parch |\n",
        "|--------|---------------------|--------|-----|-------|-------|\n",
        "| 1      | Rose Dewitt Bukater | female | 17  | 0     | 1     |\n",
        "| 3      | Jack Dawson         | male   | 21  | 0     | 0     |"
      ],
      "metadata": {
        "id": "WzVK3ySTL9lC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-27T13:13:17.031392Z",
          "iopub.status.busy": "2022-04-27T13:13:17.030737Z",
          "iopub.status.idle": "2022-04-27T13:13:17.598265Z",
          "shell.execute_reply": "2022-04-27T13:13:17.597600Z"
        },
        "papermill": {
          "duration": 0.877535,
          "end_time": "2022-04-27T13:13:17.598399",
          "exception": false,
          "start_time": "2022-04-27T13:13:16.720864",
          "status": "completed"
        },
        "tags": [],
        "id": "bVnTYJvm-S1N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "361207ed-5e5c-4f0b-fea6-7f6d9ed75a75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----------+----------------------------------------+\n",
            "|Name               |prediction|probability                             |\n",
            "+-------------------+----------+----------------------------------------+\n",
            "|Rose Dewitt Bukater|1.0       |[0.04339944669657338,0.9566005533034266]|\n",
            "|Jack Dawson        |0.0       |[0.8819617121468608,0.11803828785313915]|\n",
            "+-------------------+----------+----------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "\n",
        "new_passengers = spark.createDataFrame([\n",
        "    Row(Pclass=1, Name=\"Rose Dewitt Bukater\", Sex=\"female\", Age=17, SibSp=0, parents_children_onboard=1),\n",
        "    Row(Pclass=3, Name=\"Jack Dawson\", Sex=\"male\", Age=21, SibSp=0, parents_children_onboard=0)\n",
        "])\n",
        "\n",
        "\n",
        "new_passengers_transformed = model.transform(new_passengers)\n",
        "\n",
        "\n",
        "new_passengers_transformed.select(\"Name\", \"prediction\", \"probability\").show(truncate=False)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "papermill": {
      "duration": 244.826534,
      "end_time": "2022-04-27T13:14:16.910467",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-04-27T13:10:12.083933",
      "version": "2.1.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}