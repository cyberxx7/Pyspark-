{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQKCNuzTXrcV"
      },
      "source": [
        "## HW Assignment 2\n",
        "\n",
        "In this assignment, we will learn how to use Apache Spark DataFrames and the MLLib package used for machine learning.\n",
        "Run the code below to start up a local Spark instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPY2dYeNFjrg"
      },
      "outputs": [],
      "source": [
        "# Install Spark 3.2.4\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.4/spark-3.2.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.2.4-bin-hadoop2.7.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaNmXxGrFuCD"
      },
      "outputs": [],
      "source": [
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.4-bin-hadoop2.7\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYtoDOcLF8yq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6769f6e0-1a31-4a3f-d8bd-008ab490667c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.0-py2.py3-none-any.whl size=213793581 sha256=a681b26a5ee96d98f92d7cfbb60a6060584ccd6e7243beaa0f71bfd1d112108f\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/6f/a8/4d2c26233a51a570ccf015208651aeed4590ed3f935b70e7c6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.0\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install --upgrade pyspark==2.4.0\n",
        "!python -m pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "zRZPMwVemoY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q0DuZp2F-MX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cbcb82c-34ba-48c6-a88b-174a3b8b1a16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VU8kC2nJTUdB"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAlndDJyDuag"
      },
      "outputs": [],
      "source": [
        "APP_NAME = \"HW2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flNZrdlNDuas"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName(APP_NAME).getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTEXZ7oBUQsh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "47e38e06-1f65-4a7a-dcca-496b8164b961"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x79b9cc035870>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://2d96cd060aa6:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.4</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>HW2</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty-Hw33MVk3v"
      },
      "source": [
        "1. a. In the first part of this assignment, we will load a dataset and discover some insight about the data.\n",
        "Load the travel dataset provided in the assignment with the option inferSchema set to true. Print 20 rows from the table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42Lui7cRVbjj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f178d055-8706-439b-a936-2478579d9e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+--------------------+--------------------+-----+--------+--------------------+---------+--------------------+------+---+\n",
            "|Agency|  Agency Type|Distribution Channel|        Product Name|Claim|Duration|         Destination|Net Sales|Commision (in value)|Gender|Age|\n",
            "+------+-------------+--------------------+--------------------+-----+--------+--------------------+---------+--------------------+------+---+\n",
            "|   CBH|Travel Agency|             Offline|  Comprehensive Plan|   No|     186|            MALAYSIA|    -29.0|                9.57|     F| 81|\n",
            "|   CBH|Travel Agency|             Offline|  Comprehensive Plan|   No|     186|            MALAYSIA|    -29.0|                9.57|     F| 71|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|      65|           AUSTRALIA|    -49.5|                29.7|  null| 32|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|      60|           AUSTRALIA|    -39.6|               23.76|  null| 32|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|      79|               ITALY|    -19.8|               11.88|  null| 41|\n",
            "|   JZI|     Airlines|              Online|          Value Plan|   No|      66|       UNITED STATES|   -121.0|               42.35|     F| 44|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|      47|       UNITED STATES|    -39.6|               23.76|  null| 32|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|      63|           AUSTRALIA|   -108.9|               65.34|  null| 29|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|      57|            THAILAND|    -19.8|               11.88|  null| 44|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|     186|           AUSTRALIA|    -99.0|                59.4|  null| 37|\n",
            "|   JZI|     Airlines|              Online|          Basic Plan|   No|      33|KOREA, DEMOCRATIC...|    -26.0|                 9.1|  null|118|\n",
            "|   JZI|     Airlines|              Online|          Basic Plan|   No|       1|            MALAYSIA|    -18.0|                 6.3|     M| 47|\n",
            "|   KML|Travel Agency|              Online|        Premier Plan|   No|      53|              NORWAY|   -130.0|                49.4|     F| 48|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|       5|            MALAYSIA|    -39.6|               23.76|  null| 64|\n",
            "|   EPX|Travel Agency|              Online|2 way Comprehensi...|   No|      39|            VIET NAM|    -25.0|                 0.0|  null| 36|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|       6|             DENMARK|    -19.8|               11.88|  null| 53|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|      48|             DENMARK|    -79.2|               47.52|  null| 43|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|      11|       UNITED STATES|    -29.7|               17.82|  null| 58|\n",
            "|   JZI|     Airlines|              Online|          Basic Plan|   No|       3|            MALAYSIA|    -18.0|                 6.3|     M| 47|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|      14|            THAILAND|    -69.3|               41.58|  null| 37|\n",
            "+------+-------------+--------------------+--------------------+-----+--------+--------------------+---------+--------------------+------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.load('/content/gdrive/My Drive//travel insurance.csv', format='csv', inferSchema=True, header=True)\n",
        "\n",
        "df.show(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh4eyaogGeI-"
      },
      "source": [
        "b. Rename the Commision (in value) column to Commission. Assign this dataframe to a new variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By_M57GxGcI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "846276bd-4ef9-4689-956b-8d9904b59b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+--------------------+--------------------+-----+--------+--------------------+---------+----------+------+---+\n",
            "|Agency|  Agency Type|Distribution Channel|        Product Name|Claim|Duration|         Destination|Net Sales|Commission|Gender|Age|\n",
            "+------+-------------+--------------------+--------------------+-----+--------+--------------------+---------+----------+------+---+\n",
            "|   CBH|Travel Agency|             Offline|  Comprehensive Plan|   No|     186|            MALAYSIA|    -29.0|      9.57|     F| 81|\n",
            "|   CBH|Travel Agency|             Offline|  Comprehensive Plan|   No|     186|            MALAYSIA|    -29.0|      9.57|     F| 71|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|      65|           AUSTRALIA|    -49.5|      29.7|  null| 32|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|      60|           AUSTRALIA|    -39.6|     23.76|  null| 32|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|      79|               ITALY|    -19.8|     11.88|  null| 41|\n",
            "|   JZI|     Airlines|              Online|          Value Plan|   No|      66|       UNITED STATES|   -121.0|     42.35|     F| 44|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|      47|       UNITED STATES|    -39.6|     23.76|  null| 32|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|      63|           AUSTRALIA|   -108.9|     65.34|  null| 29|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|      57|            THAILAND|    -19.8|     11.88|  null| 44|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|     186|           AUSTRALIA|    -99.0|      59.4|  null| 37|\n",
            "|   JZI|     Airlines|              Online|          Basic Plan|   No|      33|KOREA, DEMOCRATIC...|    -26.0|       9.1|  null|118|\n",
            "|   JZI|     Airlines|              Online|          Basic Plan|   No|       1|            MALAYSIA|    -18.0|       6.3|     M| 47|\n",
            "|   KML|Travel Agency|              Online|        Premier Plan|   No|      53|              NORWAY|   -130.0|      49.4|     F| 48|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|       5|            MALAYSIA|    -39.6|     23.76|  null| 64|\n",
            "|   EPX|Travel Agency|              Online|2 way Comprehensi...|   No|      39|            VIET NAM|    -25.0|       0.0|  null| 36|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|       6|             DENMARK|    -19.8|     11.88|  null| 53|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|      48|             DENMARK|    -79.2|     47.52|  null| 43|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|      11|       UNITED STATES|    -29.7|     17.82|  null| 58|\n",
            "|   JZI|     Airlines|              Online|          Basic Plan|   No|       3|            MALAYSIA|    -18.0|       6.3|     M| 47|\n",
            "|   CWT|Travel Agency|              Online|Rental Vehicle Ex...|   No|      14|            THAILAND|    -69.3|     41.58|  null| 37|\n",
            "+------+-------------+--------------------+--------------------+-----+--------+--------------------+---------+----------+------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_renamed = df.withColumnRenamed('Commision (in value)', 'Commission')\n",
        "df_renamed.show(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eWihFKPBSLu"
      },
      "source": [
        "c. Compute the count of policies for each destination. Print the top 10 destinations by the count of policies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WZrk6i9A5t-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebb63ba6-bc95-4afb-ad60-bc0db9399b8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----+\n",
            "|  Destination|count|\n",
            "+-------------+-----+\n",
            "|    SINGAPORE|13255|\n",
            "|     MALAYSIA| 5930|\n",
            "|     THAILAND| 5894|\n",
            "|        CHINA| 4796|\n",
            "|    AUSTRALIA| 3694|\n",
            "|    INDONESIA| 3452|\n",
            "|UNITED STATES| 2530|\n",
            "|  PHILIPPINES| 2490|\n",
            "|    HONG KONG| 2411|\n",
            "|        INDIA| 2251|\n",
            "+-------------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Group by 'Destination', count the policies, and then order by count in descending order\n",
        "destination_counts = df_renamed.groupBy(\"Destination\").count().orderBy(col(\"count\").desc())\n",
        "\n",
        "# Show the top 10 destinations by policy count\n",
        "destination_counts.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj84BNtRCKYW"
      },
      "source": [
        "d. What is the mean age for customers who filed a claim? What is the mean age for customers who did not file a claim?\n",
        "Print the mean age for both customers who filed and those who didn't file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhAB16rYB1_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ce5294-a97b-453f-8829-3978e93ea273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------------+\n",
            "|Claim|          Mean Age|\n",
            "+-----+------------------+\n",
            "|   No|39.989823554864664|\n",
            "|  Yes| 38.63430420711974|\n",
            "+-----+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import mean\n",
        "\n",
        "\n",
        "mean_age_by_claim_status = df_renamed.groupBy(\"Claim\").agg(mean(\"Age\").alias(\"Mean Age\"))\n",
        "\n",
        "# Show the mean age for both groups\n",
        "mean_age_by_claim_status.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UUtD8a4GErh"
      },
      "source": [
        "e. Which travel agency made the most amount of money in commission? Compute the total amount of commission for each agency and print the top 10 agencies ordered by the amount."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUHWry29F__S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7f71793-39fd-44f1-e295-b5295aaba443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------------+\n",
            "|Agency|  Total Commission|\n",
            "+------+------------------+\n",
            "|   CWT|277825.68000001844|\n",
            "|   C2B|169747.34000000358|\n",
            "|   JZI| 74471.24999999916|\n",
            "|   LWC| 51169.12999999995|\n",
            "|   JWT|16208.399999999956|\n",
            "|   KML| 8550.380000000014|\n",
            "|   TST|           5556.25|\n",
            "|   RAB| 5239.199999999985|\n",
            "|   ART|3493.3499999999995|\n",
            "|   ADM| 3136.899999999999|\n",
            "+------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "total_commission_by_agency = df_renamed.groupBy(\"Agency\").sum(\"Commission\").withColumnRenamed(\"sum(Commission)\", \"Total Commission\")\n",
        "\n",
        "# Order the results to get the top 10 agencies by total commission\n",
        "top_agencies_by_commission = total_commission_by_agency.orderBy(\"Total Commission\", ascending=False)\n",
        "\n",
        "# Show the top 10 agencies\n",
        "top_agencies_by_commission.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fouWZgQpL0T0"
      },
      "source": [
        "2. a. The second part of the assignment will be to create a transformation pipeline. Remove all rows with missing data, convert all strings to integers, create dummy variables and assemble a feature vector. Use only the following variables as predictors: Agency Type, Distribution Channel, Duration, Net Sales, Commission, Gender, Age. Use Claim as the response variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWi3vXGIQBw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a270a64-e4e9-4337-e233-9b48434e72e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|[0.0,0.0,186.0,-2...|  0.0|\n",
            "|[0.0,0.0,186.0,-2...|  0.0|\n",
            "|[1.0,1.0,66.0,-12...|  0.0|\n",
            "|[1.0,1.0,1.0,-18....|  0.0|\n",
            "|[0.0,1.0,53.0,-13...|  0.0|\n",
            "|[1.0,1.0,3.0,-18....|  0.0|\n",
            "|[1.0,1.0,12.0,46....|  0.0|\n",
            "|[1.0,1.0,7.0,17.5...|  0.0|\n",
            "|[1.0,1.0,12.0,94....|  1.0|\n",
            "|[1.0,1.0,190.0,29...|  0.0|\n",
            "|[1.0,1.0,364.0,38...|  0.0|\n",
            "|[1.0,1.0,11.0,50....|  0.0|\n",
            "|[1.0,1.0,4.0,15.0...|  0.0|\n",
            "|[1.0,1.0,45.0,26....|  0.0|\n",
            "|[1.0,1.0,181.0,30...|  0.0|\n",
            "|[1.0,1.0,5.0,22.0...|  0.0|\n",
            "|[1.0,1.0,22.0,18....|  0.0|\n",
            "|[1.0,1.0,76.0,35....|  0.0|\n",
            "|[1.0,1.0,41.0,44....|  0.0|\n",
            "|[1.0,1.0,43.0,22....|  0.0|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "df_clean = df_renamed.na.drop()\n",
        "\n",
        "# Convert string columns to integer values (StringIndexer) and create dummy variables (OneHotEncoder)\n",
        "agency_type_indexer = StringIndexer(inputCol=\"Agency Type\", outputCol=\"Agency Type Index\")\n",
        "distribution_channel_indexer = StringIndexer(inputCol=\"Distribution Channel\", outputCol=\"Distribution Channel Index\")\n",
        "gender_indexer = StringIndexer(inputCol=\"Gender\", outputCol=\"Gender Index\")\n",
        "\n",
        "agency_type_encoder = OneHotEncoder(inputCol=\"Agency Type Index\", outputCol=\"Agency Type Vec\")\n",
        "distribution_channel_encoder = OneHotEncoder(inputCol=\"Distribution Channel Index\", outputCol=\"Distribution Channel Vec\")\n",
        "gender_encoder = OneHotEncoder(inputCol=\"Gender Index\", outputCol=\"Gender Vec\")\n",
        "\n",
        "# Assemble the feature vector\n",
        "feature_assembler = VectorAssembler(\n",
        "    inputCols=[\"Agency Type Vec\", \"Distribution Channel Vec\", \"Duration\", \"Net Sales\", \"Commission\", \"Gender Vec\", \"Age\"],\n",
        "    outputCol=\"features\")\n",
        "\n",
        "# Set Claim as the response variable\n",
        "label_indexer = StringIndexer(inputCol=\"Claim\", outputCol=\"label\")\n",
        "\n",
        "# Define the pipeline\n",
        "pipeline = Pipeline(stages=[agency_type_indexer, distribution_channel_indexer, gender_indexer,\n",
        "                            agency_type_encoder, distribution_channel_encoder, gender_encoder,\n",
        "                            feature_assembler, label_indexer])\n",
        "\n",
        "# Fit the pipeline to the data\n",
        "pipeline_model = pipeline.fit(df_clean)\n",
        "\n",
        "# Transform the data\n",
        "df_transformed = pipeline_model.transform(df_clean)\n",
        "\n",
        "# The resulting DataFrame\n",
        "df_transformed.select(\"features\", \"label\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0URLcBKQRTr"
      },
      "source": [
        "b. Split the data into train and test with 20% of the data in the test sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9O0uGpsyPvja"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_data, test_data = df_clean.randomSplit([0.8, 0.2], seed=1234)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZO0-6vhTutB"
      },
      "source": [
        "c. Apply a logistic regression model to predict the probaility that a customer will make a claim. Use the training data to produce a model and then test it using the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMKGOShLT6FQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48e04c2e-1e21-4fb7-a848-a7d31a2c8a5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+--------------------+\n",
            "|prediction|label|            features|\n",
            "+----------+-----+--------------------+\n",
            "|       0.0|  0.0|[0.0,1.0,7.0,86.0...|\n",
            "|       0.0|  0.0|[0.0,1.0,16.0,-86...|\n",
            "|       0.0|  0.0|[0.0,1.0,197.0,86...|\n",
            "|       0.0|  0.0|[0.0,1.0,30.0,130...|\n",
            "|       0.0|  0.0|[0.0,1.0,49.0,0.0...|\n",
            "+----------+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Test Data Accuracy: 0.7284892741500263\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "\n",
        "pipeline_model = pipeline.fit(df_clean)\n",
        "df_transformed = pipeline_model.transform(df_clean)\n",
        "\n",
        "\n",
        "# Split the transformed data into train and test sets\n",
        "train_data, test_data = df_transformed.randomSplit([0.8, 0.2], seed=1234)\n",
        "\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
        "lr_model = lr.fit(train_data)\n",
        "\n",
        "\n",
        "test_predictions = lr_model.transform(test_data)\n",
        "test_predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
        "\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator()\n",
        "test_accuracy = evaluator.evaluate(test_predictions)\n",
        "print(f\"Test Data Accuracy: {test_accuracy}\")\n",
        "\n",
        "train_predictions = lr_model.transform(train_data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa3Egw3JT7sQ"
      },
      "source": [
        "d. Compute the accuracy for the train and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxymZW1KT66b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63ad8ca7-fc2e-485d-b808-a1cd9e9ff64d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Accuracy: 0.9644128113879004\n",
            "Test Data Accuracy: 0.9670085943997782\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "\n",
        "train_predictions = lr_model.transform(train_data)\n",
        "\n",
        "\n",
        "train_accuracy = evaluator.evaluate(train_predictions)\n",
        "print(f\"Training Data Accuracy: {train_accuracy}\")\n",
        "\n",
        "\n",
        "test_predictions = lr_model.transform(test_data)\n",
        "\n",
        "test_accuracy = evaluator.evaluate(test_predictions)\n",
        "print(f\"Test Data Accuracy: {test_accuracy}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}